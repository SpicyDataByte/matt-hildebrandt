{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrape Cattle Market Reports for a Given Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](cattle.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import requests \n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Scraping Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_filename(filename):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
    "\n",
    "def create_output_directory(location):\n",
    "    today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    directory_name = f\"{today_date}_{location}_cattle_sales\"\n",
    "    os.makedirs(directory_name, exist_ok=True)\n",
    "    return directory_name\n",
    "\n",
    "def click_link(driver, href):\n",
    "    element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, f\"//a[contains(@href, '{href.split('auctionId=')[1]}')]\"))\n",
    "    )\n",
    "    element.click()\n",
    "\n",
    "def extract_sale_date(soup):\n",
    "    return soup.find('h3', class_='sc-blLsxD kXGvid').text.strip()\n",
    "\n",
    "def extract_table_data(soup):\n",
    "    table = soup.find('table', {'class': 'sc-rZqKh kUEjMi'})\n",
    "    headers = [header.text.strip() for header in table.find('thead').find('tr').find_all('td')]\n",
    "    data_rows = table.find('tbody').find_all('tr')\n",
    "    all_data = [[cell.text.strip() for cell in row.find_all('td')] for row in data_rows]\n",
    "    return headers, all_data\n",
    "\n",
    "def write_to_csv(output_dir, date_of_sale, headers, data):\n",
    "    headers.append('DateOfSale')\n",
    "    for row in data:\n",
    "        row.append(date_of_sale)\n",
    "    sanitized_date = sanitize_filename(date_of_sale)\n",
    "    csv_path = os.path.join(output_dir, f\"{sanitized_date}.csv\")\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def process_sales_data(driver, href_dict, location):\n",
    "    output_dir = create_output_directory(location)\n",
    "    for text, href in href_dict.items():\n",
    "        if location.lower() in text.lower():\n",
    "            click_link(driver, href)\n",
    "            time.sleep(6)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            date_of_sale = extract_sale_date(soup)\n",
    "            headers, data = extract_table_data(soup)\n",
    "            write_to_csv(output_dir, date_of_sale, headers, data)\n",
    "            time.sleep(3)\n",
    "            driver.back()\n",
    "            time.sleep(3)\n",
    "\n",
    "def fetch_href_dict(driver, url, xpath):\n",
    "    driver.get(url)\n",
    "    print(driver.title)\n",
    "    td_elements = driver.find_elements(By.XPATH, xpath)\n",
    "    href_dict = {td.text.strip(): td.get_attribute(\"href\") for td in td_elements}\n",
    "    return href_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Web Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"virden\"\n",
    "url = \"https://dlms.ca/Report/MarketReport\"\n",
    "xpath = \"//td/a\"\n",
    "\n",
    "# Set up WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    # Fetch href_dict\n",
    "    href_dict = fetch_href_dict(driver, url, xpath)\n",
    "\n",
    "    # Process sales data\n",
    "    process_sales_data(driver, href_dict, location)\n",
    "\n",
    "finally:\n",
    "    # Quit the WebDriver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = f''\n",
    "\n",
    "\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)  # Read the CSV file into a dataframe\n",
    "    df_list.append(df)  # Append the dataframe to the list\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "output_file_path = f'c:\\\\combined_{location}_cattle_sales.csv'\n",
    "\n",
    "\n",
    "combined_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq#             int64\n",
       "Lot#             int64\n",
       "Pen #           object\n",
       "Head             int64\n",
       "Sex             object\n",
       "Breed           object\n",
       "Avg. Weight      int64\n",
       "Total Weight     int64\n",
       "Price           object\n",
       "DateOfSale      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
