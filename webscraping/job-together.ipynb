{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://jobgether.com/top-100-flexible-employers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = requests.get(url).text \n",
    "soup = BeautifulSoup(data,\"html5lib\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import *\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Remote and Flexible Companies in the World\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\\\Program Files (x86)\\\\chromedriver.exe\"\n",
    "# driver = webdriver.Chrome(PATH)\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       company_name Job_Overall                           industry  \\\n",
      "0    chainlink labs    #91 JOBS  Information Technology & Services   \n",
      "1            Zapier     #8 JOBS           Computer Software / SaaS   \n",
      "2        Automattic    #10 JOBS                           Internet   \n",
      "3               N/A    #38 JOBS           Computer Software / SaaS   \n",
      "4            GitLab   #155 JOBS  Information Technology & Services   \n",
      "..              ...         ...                                ...   \n",
      "93   Namecheap, Inc     #0 JOBS  Information Technology & Services   \n",
      "94              5CA     #2 JOBS                Facility Management   \n",
      "95  insightsoftware    #49 JOBS           Computer Software / SaaS   \n",
      "96          Elastic    #24 JOBS           Computer Software / SaaS   \n",
      "97     MeridianLink     #8 JOBS                                      \n",
      "\n",
      "         flex_score  \n",
      "0   90.8%FLEX SCORE  \n",
      "1   90.0%FLEX SCORE  \n",
      "2   89.8%FLEX SCORE  \n",
      "3   88.9%FLEX SCORE  \n",
      "4   86.7%FLEX SCORE  \n",
      "..              ...  \n",
      "93  78.4%FLEX SCORE  \n",
      "94  78.3%FLEX SCORE  \n",
      "95  78.3%FLEX SCORE  \n",
      "96  78.3%FLEX SCORE  \n",
      "97  78.1%FLEX SCORE  \n",
      "\n",
      "[98 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "labels_desktop_div = soup.find_all('div', id='labels_desktop')\n",
    "\n",
    "# Initialize lists to store data\n",
    "company_names = []\n",
    "job_overalls = []\n",
    "industries = []\n",
    "flex_scores = []\n",
    "\n",
    "# Iterate over each div in labels_desktop_div\n",
    "for div in labels_desktop_div:\n",
    "    company_name = div.find(class_='title-company-normal')\n",
    "    job_overall = div.find(class_='total-jobs text-primary')\n",
    "    industry = div.find(class_='title-industry non-selectable')\n",
    "    \n",
    "    # Append text if element is found, else append None or a default value\n",
    "    company_names.append(company_name.text if company_name else 'N/A')\n",
    "    job_overalls.append(job_overall.text if job_overall else 'N/A')\n",
    "    industries.append(industry.text if industry else 'N/A')\n",
    "\n",
    "# Extract flex scores separately since they are not within labels_desktop_div\n",
    "flex_scores = [element.text for element in soup.find_all(class_='percent-flex-score non-selectable')]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    'company_name': company_names,\n",
    "    'Job_Overall': job_overalls,\n",
    "    'industry': industries,\n",
    "    'flex_score': flex_scores\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "98\n",
      "98\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(company_names))\n",
    "print(len(job_overalls))\n",
    "print(len(industries))\n",
    "print(len(flex_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('top-100-flex-companies-1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
